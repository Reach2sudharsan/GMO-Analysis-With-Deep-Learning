{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import numpy as np\n",
    "# your Twitter API key and API secret\n",
    "my_api_key = \"Top Secret\"\n",
    "my_api_secret = \"Top Secret\"\n",
    "# authenticate\n",
    "auth = tw.OAuthHandler(my_api_key, my_api_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"#GMOs\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy1 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy1.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"Genetic Engineering\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy2 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy2.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"NonGMO\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy3 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy3.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"biotechnology\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy4 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy4.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"transgenic\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy5 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy5.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"bioengineered\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy6 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy6.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"gene-spliced\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy7 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy7.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"gm seeds\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy8 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy8.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n",
      "Rate limit reached. Sleeping for: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# store the API responses in a list\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m tweets_copy9 \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     tweets_copy9\u001b[39m.\u001b[39mappend(tweet)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTotal Tweets fetched:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(tweets_copy9))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tweepy/cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tweepy/cursor.py:286\u001b[0m, in \u001b[0;36mItemIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpage_index \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Reached end of current page, get the next page...\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpage_iterator)\n\u001b[1;32m    287\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpage_iterator)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tweepy/cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tweepy/cursor.py:167\u001b[0m, in \u001b[0;36mIdIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 167\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmethod(max_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_id, parser\u001b[39m=\u001b[39;49mRawParser(), \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m    169\u001b[0m     model \u001b[39m=\u001b[39m ModelParser()\u001b[39m.\u001b[39mparse(\n\u001b[1;32m    170\u001b[0m         data, api \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    171\u001b[0m         payload_list\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_list,\n\u001b[1;32m    172\u001b[0m         payload_type\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_type\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    174\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mparser\u001b[39m.\u001b[39mparse(\n\u001b[1;32m    175\u001b[0m         data, api \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    176\u001b[0m         payload_list\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_list,\n\u001b[1;32m    177\u001b[0m         payload_type\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_type\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tweepy/api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(method)\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tweepy/api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_list\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_list\n\u001b[1;32m     45\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_type\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tweepy/api.py:1303\u001b[0m, in \u001b[0;36mAPI.search_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39m@pagination\u001b[39m(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1210\u001b[0m \u001b[39m@payload\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msearch_results\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch_tweets\u001b[39m(\u001b[39mself\u001b[39m, q, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1212\u001b[0m     \u001b[39m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[39m                     until, since_id, max_id, include_entities)\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[39m    .. _Twitter's documentation on the standard search API: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m   1304\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msearch/tweets\u001b[39;49m\u001b[39m'\u001b[39;49m, endpoint_parameters\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   1305\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mq\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgeocode\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlang\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlocale\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mresult_type\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcount\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m   1306\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39muntil\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msince_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmax_id\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39minclude_entities\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m   1307\u001b[0m         ), q\u001b[39m=\u001b[39;49mq, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   1308\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tweepy/api.py:207\u001b[0m, in \u001b[0;36mAPI.request\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[39mif\u001b[39;00m sleep_time \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    206\u001b[0m         log\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRate limit reached. Sleeping for: \u001b[39m\u001b[39m{\u001b[39;00msleep_time\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m         time\u001b[39m.\u001b[39;49msleep(sleep_time \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)  \u001b[39m# Sleep for extra sec\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m# Apply authentication\u001b[39;00m\n\u001b[1;32m    210\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search_query = \"organic food\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(2000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy9 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy9.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"DNA\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(1000)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy10 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy10.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_copy = np.concatenate((tweets_copy1, tweets_copy2, tweets_copy3, tweets_copy4, tweets_copy5, tweets_copy6,\n",
    "tweets_copy7, tweets_copy8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_copy = np.concatenate((tweets_copy1, tweets_copy2, tweets_copy3, tweets_copy4, tweets_copy5, tweets_copy6,\n",
    "tweets_copy7, tweets_copy8, tweets_copy9, tweets_copy10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets_copy = tweets_copy.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets_copy = np.unique(new_tweets_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_tweets_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Tweets DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('tweets_copy.pickle', 'ab')\n",
    "pickle.dump(tweets_copy, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# intialize the dataframe\n",
    "tweets_df = pd.DataFrame()\n",
    "\n",
    "# populate the dataframe\n",
    "for tweet in tweets_copy:\n",
    "    hashtags = []\n",
    "    try:\n",
    "        for hashtag in tweet.entities[\"hashtags\"]:\n",
    "            hashtags.append(hashtag[\"text\"])\n",
    "        text = api.get_status(id=tweet.id, tweet_mode='extended').full_text\n",
    "    except:\n",
    "        pass\n",
    "    tweets_df = tweets_df.append(pd.DataFrame({'user_name': tweet.user.name, \n",
    "                                               'user_location': tweet.user.location,\\\n",
    "                                               'user_description': tweet.user.description,\n",
    "                                               'user_verified': tweet.user.verified,\n",
    "                                               'date': tweet.created_at,\n",
    "                                               'text': text, \n",
    "                                               'hashtags': [hashtags if hashtags else None],\n",
    "                                               'source': tweet.source}))\n",
    "    tweets_df = tweets_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array(tweets_df['user_location'])\n",
    "len(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = np.unique(np.array(tweets_df['user_location']))\n",
    "len(a2)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('GMO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
