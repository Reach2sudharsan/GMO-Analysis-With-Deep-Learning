{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import numpy as np\n",
    "# your Twitter API key and API secret\n",
    "my_api_key = \" \"\n",
    "my_api_secret = \" \"\n",
    "# authenticate\n",
    "auth = tw.OAuthHandler(my_api_key, my_api_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets fetched: 400\n"
     ]
    }
   ],
   "source": [
    "search_query = \"#GMOs\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(400)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy1 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy1.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected parameter: since\n",
      "Unexpected parameter: since\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tweets fetched: 5\n"
     ]
    }
   ],
   "source": [
    "search_query = \"#GM Crops\"\n",
    "\n",
    "# get tweets from the API\n",
    "tweets = tw.Cursor(api.search_tweets,\n",
    "              q=search_query,\n",
    "              lang=\"en\",\n",
    "              since=\"2016-09-16\").items(400)\n",
    "\n",
    "# store the API responses in a list\n",
    "tweets_copy2 = []\n",
    "for tweet in tweets:\n",
    "    tweets_copy2.append(tweet)\n",
    "    \n",
    "print(\"Total Tweets fetched:\", len(tweets_copy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_copy = np.concatenate((tweets_copy1, tweets_copy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/jxk5_ydd4zl7c_t8ktc70vnw0000gn/T/ipykernel_61550/1880315750.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tweets_df = tweets_df.append(pd.DataFrame({'user_name': tweet.user.name,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# intialize the dataframe\n",
    "tweets_df = pd.DataFrame()\n",
    "\n",
    "# populate the dataframe\n",
    "for tweet in tweets_copy:\n",
    "    hashtags = []\n",
    "    try:\n",
    "        for hashtag in tweet.entities[\"hashtags\"]:\n",
    "            hashtags.append(hashtag[\"text\"])\n",
    "        text = api.get_status(id=tweet.id, tweet_mode='extended').full_text\n",
    "    except:\n",
    "        pass\n",
    "    tweets_df = tweets_df.append(pd.DataFrame({'user_name': tweet.user.name, \n",
    "                                               'user_location': tweet.user.location,\\\n",
    "                                               'user_description': tweet.user.description,\n",
    "                                               'user_verified': tweet.user.verified,\n",
    "                                               'date': tweet.created_at,\n",
    "                                               'text': text, \n",
    "                                               'hashtags': [hashtags if hashtags else None],\n",
    "                                               'source': tweet.source}))\n",
    "    tweets_df = tweets_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tweets_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets_df' is not defined"
     ]
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.array(tweets_df['user_location'])\n",
    "len(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', ' Puerto Vallarta, Jalisco.', '#ElPasoStrong ',\n",
       "       '* many rocks to stand on', '27km, Gayaza-Zirobwe road ',\n",
       "       '3eme planète de Sol', 'A Triangle ', 'A cabin deep in the woods',\n",
       "       'AZ', 'Accra, Ghana', 'Andhra Pradesh, India', 'Angers, France',\n",
       "       'Antarctica', 'Antwerpen, België', 'Arizona 🌵', 'Arkansas, USA',\n",
       "       'Asia', 'Bala Cynwyd, PA ', 'Barcelona, Spain', 'Bayern',\n",
       "       'Belgique', 'Bengaluru', 'Berlin', 'Berlin, Germany', 'Birmingham',\n",
       "       'Bolivia', 'Bridgewater, Nova Scotia', 'Brisbane, Queensland',\n",
       "       'Brookings, SD', 'Buffalo, NY', 'By the beautiful Hudson River.',\n",
       "       'Calgary, Alberta', 'California', 'Canada', 'Cape Town',\n",
       "       'Cassopolis MI', 'Chalmette, LA', 'Chelmsford', 'Chelsea', 'Chile',\n",
       "       'Cincinnati, OH', 'Co. Dublin Ireland. No DMs pls',\n",
       "       'College Park, MD', 'Colorado, USA', 'Connecticut, USA',\n",
       "       'Covington, GA', 'D.C., Missouri, & Sacramento',\n",
       "       'Daintree, Queesland, Australia', 'Davenport, CA',\n",
       "       'DeSantistan Fascist territory,', 'Debunking Denialism',\n",
       "       'Delft, Nederland', 'Delhi', 'Dublin City, Ireland', 'Earth',\n",
       "       'Earth/Your Inbox', 'East Anglia', 'East Region ',\n",
       "       'Eastern Kentucky, USA', 'England, United Kingdom',\n",
       "       \"Est Jan 1997 to fight GMO's\", 'Everywhere.',\n",
       "       'Florence - Italy, Brussels - B', 'Georgia, USA',\n",
       "       'Germany, Bavaria', 'Global', 'God’s Country', 'Greece',\n",
       "       'Gulu, Uganda', 'Guwahati', 'HYDERABAD', 'Hanumangarh,Bharat',\n",
       "       'Harare, Zimbabwe', 'Honduras', 'Honolulu, HI', 'Houston',\n",
       "       'Hyderabad, India', 'Hyderabad, Telangana',\n",
       "       \"I'm currently where I'm at\", 'In Scotland #IStandWithUkraine',\n",
       "       'In ur head rent free', 'In-A-Gadda-Da-Vida', 'India',\n",
       "       'Indiana, USA', 'Ingles Markets ', 'Ipswich, England', 'Italy',\n",
       "       'Ithaca, NY', 'Japan', 'Kampala, Uganda', 'Kansas City, MO',\n",
       "       'Keller,FtWorth,TX', 'Kent,UK', 'Kentucky, USA',\n",
       "       'Kuala Lumpur City, Kuala Lumpu', 'Langtoun, UK', 'Las Vegas, NV',\n",
       "       'Leipzig, Germany', 'London ENTREPRENEUR',\n",
       "       'London Earls Court sw5', 'London, England', 'London, UK',\n",
       "       'Los Alamos, NM', 'Los Angeles', 'Los Angeles, CA',\n",
       "       'Los Banos, Laguna, Philippines', 'Marysville, WA', \"Mi'kma'ki\",\n",
       "       'Michigan, USA', 'Milan, Italy', 'Milky Way', 'Milwaukee, WI',\n",
       "       'Minnesota and Wisconsin', 'Moscow, Russia', 'Mountain View, CA',\n",
       "       'Multi-location', 'Munich, Germany 🇩🇪', 'MyinnerHeavenwth susanoo',\n",
       "       'NEBRASKA, USA', 'NJ', 'NYC', 'NaCRRI-Namulonge', 'Nairobi, Kenya',\n",
       "       'Namulonge', 'New Jersey', 'Norddeutschland',\n",
       "       'North Carolina, USA', 'Northern Monkey',\n",
       "       'On The Moon ... Literally.', 'Oregon, USA', 'Panamá', 'Paris',\n",
       "       'Paris, France', 'Pennsylania, USA', 'Planet Earth',\n",
       "       'Planet Earth ', 'Pluto ', 'Puerto Rico, CT, USA',\n",
       "       'Quebec, Mexico, Philippines...', 'Roaming ', 'Roanoke, VA',\n",
       "       'SE Qld, Australia', 'Seattle', 'Seattle, WA',\n",
       "       'Sheffield,Notts,London, USA', 'So-called Canada',\n",
       "       'Solano County, CA', 'Somewhere Around The World.',\n",
       "       'Somewhere in Texas. Anywhere', 'South Africa',\n",
       "       'South Florida USA', 'South Tampa, Florida',\n",
       "       'SouthCentral California Coastl', 'Stamford, CT', 'Sukhothai',\n",
       "       'Tainan', 'Telegram: @Maxmedieval', 'The Dreamtime',\n",
       "       'Timmins, Ontario', 'Tokyo, Japan', 'Toronto, Canada',\n",
       "       'Toronto, ON ', 'TreeHugger', 'UK', 'US', 'USA', 'United States',\n",
       "       'UnitedStates', 'University of Arkansas', 'Usedom', 'VA',\n",
       "       'Vancouver, BC', 'Vermont, USA', 'Vermont/Brazil',\n",
       "       'Vic (Osona) - Catalunya', 'Virginia', 'Voice for the voiceless 🐽',\n",
       "       'WALDPORT, OR', 'WORLDWIDE LYON VENICE HAWAII', 'Washington, DC',\n",
       "       'Winchester, VA', 'Windsor, Ontario', 'Winnipeg',\n",
       "       'Worcester, MA; Agotime, Ghana', 'Worldwide', 'Zona de pastizal',\n",
       "       'Zürich, Schweiz', 'planet earth - milk way galaxy',\n",
       "       'third rock from the sun', 'İzmir, Türkiye',\n",
       "       '♌︎ ♊︎ ♎︎ || ♋︎ ♉︎ ♍︎ ', '⚡ India ', '🏔Pyramid🛖Mounds⛰⚜904👑📿👁❤U'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = np.unique(np.array(tweets_df['user_location']))\n",
    "len(a2)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('GMO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sudharsangopalakrishnan/GMO-Analysis-With-Deep-Learning/data-setup/getting-tweets.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tweets_copy\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets_copy' is not defined"
     ]
    }
   ],
   "source": [
    "tweets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
